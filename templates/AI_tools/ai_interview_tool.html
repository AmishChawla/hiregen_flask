
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Interviewer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            colors: {
              primary: '#4f46e5',
              secondary: '#6366f1',
              danger: '#ef4444',
            },
          },
        },
      };
    </script>
    <style>
      .active-speaker {
        box-shadow: 0 0 40px 12px rgba(0, 255, 0, 0.9);
        border: 4px solid lime;
      }
    </style>
  </head>
  <body class="bg-gray-950 text-white antialiased">
    <div class="flex flex-col h-screen">
      <!-- Top Bar -->
      <header class="flex items-center justify-between bg-gray-900 px-6 py-4 shadow-lg">
        <h1 class="text-2xl font-semibold tracking-tight">AI Interviewer</h1>
        <button id="endInterview" class="bg-danger hover:bg-red-700 text-white font-medium px-4 py-2 rounded-lg transition">End Interview</button>
      </header>

      <!-- Action Hint -->
      <div class="bg-gray-800 text-center text-sm text-gray-400 py-2">
        Press <kbd class="bg-gray-700 px-2 py-1 rounded text-xs">R</kbd> to toggle speaking
      </div>

      <!-- Main Content -->
      <main class="flex flex-1 overflow-hidden">
        <!-- Video/Audio Tiles -->
        <section class="flex-1 grid grid-cols-1 sm:grid-cols-2 xl:grid-cols-3 gap-6 p-4 bg-black overflow-y-auto">
          <!-- Candidate Tile -->
          <div id="userTile" class="relative bg-gray-800 rounded-2xl shadow-lg aspect-[4/5] flex items-center justify-center overflow-hidden">
            <video id="userVideo" class="absolute inset-0 w-full h-full object-cover rounded-2xl hidden" autoplay muted playsinline></video>
            <div id="userAvatar" class="absolute inset-0 flex items-center justify-center text-5xl font-bold bg-yellow-700 text-white rounded-2xl">
              <span>U</span>
            </div>
          </div>

          <!-- Screen Share Tile -->
          <div id="screenTile" class="relative bg-gray-800 rounded-2xl shadow-lg aspect-[4/5] flex items-center justify-center hidden overflow-hidden">
            <video id="screenVideo" class="w-full h-full object-cover rounded-2xl" autoplay muted playsinline></video>
          </div>

          <!-- AI Tile -->
          <div id="aiTile" class="bg-indigo-600 rounded-2xl shadow-lg aspect-[4/5] flex items-center justify-center text-white text-5xl font-bold">
            <span>AI</span>
          </div>
        </section>

        <!-- Sidebar: Transcript -->
        <aside class="w-full md:w-1/3 bg-gray-900 p-6 overflow-y-auto">
          <h2 class="text-xl font-semibold mb-4 border-b border-gray-700 pb-2">Transcript</h2>
          <div id="conversation" class="space-y-4 text-sm text-gray-300"></div>
        </aside>
      </main>

      <!-- Upload Modal -->
      <div id="fileUploadModal" class="fixed inset-0 z-50 bg-black/80 flex items-center justify-center">
        <div class="bg-gray-800 p-6 rounded-2xl w-96 space-y-4 shadow-2xl">
          <h2 class="text-xl font-semibold text-center">Upload Required Files</h2>
          <div>
            <label class="block mb-1 text-sm">Job Description (.txt)</label>
            <input type="file" id="jobFile" accept=".txt" class="w-full bg-gray-700 text-white px-3 py-2 rounded" />
          </div>
          <div>
            <label class="block mb-1 text-sm">Resume (.txt)</label>
            <input type="file" id="resumeFile" accept=".txt" class="w-full bg-gray-700 text-white px-3 py-2 rounded" />
          </div>
          <button id="startInterviewBtn" class="w-full bg-green-600 hover:bg-green-700 py-2 rounded-lg text-white font-medium transition">
            Start Interview
          </button>
        </div>
      </div>

      <!-- Evaluation Modal -->
      <div id="evaluationModal" class="fixed inset-0 bg-black/50 hidden z-50 flex items-center justify-center">
        <div class="bg-white text-black rounded-2xl w-full max-w-2xl max-h-[90vh] p-6 overflow-y-auto relative">
          <button onclick="closeModal()" class="absolute top-3 right-3 text-gray-500 hover:text-gray-700 text-2xl">&times;</button>
          <h2 class="text-xl font-bold mb-4">Final Interview Evaluation</h2>
          <div id="evaluationSpinner" class="flex justify-center py-8">
            <div class="h-10 w-10 border-t-4 border-blue-500 border-opacity-50 rounded-full animate-spin"></div>
          </div>
          <div id="evaluationContent" class="whitespace-pre-line text-sm hidden"></div>
        </div>
      </div>

<!-- Device Check Modal -->
<div id="deviceCheckModal" class="fixed inset-0 z-50 bg-black/80 flex items-center justify-center hidden">
  <div class="bg-gray-800 text-white p-6 rounded-2xl w-full max-w-xl space-y-6 shadow-2xl">
    <h2 class="text-xl font-semibold text-center">Device Setup</h2>

    <!-- Device Selectors -->
    <div class="flex flex-col md:flex-row gap-4">
      <div class="flex-1">
        <label class="block text-sm mb-1">Select Camera</label>
        <select id="cameraSelect" class="w-full bg-gray-700 text-white p-2 rounded"></select>
      </div>
      <div class="flex-1">
        <label class="block text-sm mb-1">Select Microphone</label>
        <select id="micSelect" class="w-full bg-gray-700 text-white p-2 rounded"></select>
      </div>
    </div>

    <!-- Live Preview -->
    <div class="flex flex-col md:flex-row gap-6 mt-4 items-center">
      <div class="w-full md:w-1/2">
        <label class="block text-sm mb-1">Camera Preview</label>
        <video id="cameraPreview" class="w-full rounded-lg border border-gray-600" autoplay muted playsinline></video>
        <p id="cameraStatus" class="text-xs text-gray-400 mt-1">Awaiting camera access...</p>
      </div>

      <div class="w-full md:w-1/2">
        <label class="block text-sm mb-1">Mic Test</label>
        <div class="w-full h-3 bg-gray-600 rounded overflow-hidden mt-1">
          <div id="micVolumeBar" class="h-full bg-green-500 transition-all" style="width: 0%"></div>
        </div>
        <p id="micStatus" class="text-xs text-gray-400 mt-1">Awaiting mic access...</p>

        <label class="block text-sm mt-4 mb-1">Screen Share Test</label>
        <button id="shareScreenBtn" class="bg-blue-600 hover:bg-blue-700 text-white text-sm px-3 py-1 rounded-lg">
          Share Screen
        </button>
        <p id="screenShareStatus" class="text-xs text-gray-400 mt-1">Not shared</p>
      </div>
    </div>

    <!-- Confirm Button -->
    <button id="confirmStartBtn" class="w-full bg-green-600 hover:bg-green-700 py-2 rounded-lg text-white font-medium transition">
      Start Interview
    </button>
  </div>
</div>

    </div>
  </body>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let analyser, dataArray, audioContext, micSource;
    let isRecording = false;
    let mediaStream;
    let screenStream;
    let cameraStream;
    let combinedStream;
  
    // Block auto-start of interview
    let interviewReady = false;
  
    async function fetchFirstQuestion() {
      if (!interviewReady) return;
  
      const res = await fetch('/ai/interview/get_first_question');
      const data = await res.json();
      addMessage('Interviewer', data.question);
      speak(data.question);
    }
  
    function addMessage(sender, text) {
      const convo = document.getElementById('conversation');
      const msg = document.createElement('div');
      msg.innerHTML = `<p><strong>${sender}:</strong> ${text}</p>`;
      convo.appendChild(msg);
      convo.scrollTop = convo.scrollHeight;
    }
  
    function highlightSpeaker(role) {
      const tileId = role === 'user' ? 'userTile' : 'aiTile';
      document.getElementById(tileId)?.classList.add('active-speaker');
    }
  
    function unhighlightSpeaker(role) {
      const tileId = role === 'user' ? 'userTile' : 'aiTile';
      document.getElementById(tileId)?.classList.remove('active-speaker');
    }
  
    function speak(text) {
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
        const utter = new SpeechSynthesisUtterance(text);
  
        highlightSpeaker('ai');
        utter.onend = () => {
          unhighlightSpeaker('ai');
          clearTimeout(fallbackTimeout);
        };
        utter.onerror = () => {
          unhighlightSpeaker('ai');
          clearTimeout(fallbackTimeout);
        };
        const fallbackTimeout = setTimeout(() => {
          unhighlightSpeaker('ai');
        }, 10000);
        window.speechSynthesis.speak(utter);
      }
    }
  
    async function startMicVisualizer(stream) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      micSource = audioContext.createMediaStreamSource(stream);
      micSource.connect(analyser);
      analyser.fftSize = 256;
      const bufferLength = analyser.frequencyBinCount;
      dataArray = new Uint8Array(bufferLength);
  
      function animate() {
        analyser.getByteFrequencyData(dataArray);
        const volume = dataArray.reduce((a, b) => a + b) / bufferLength;
        const scale = 1 + Math.min(volume / 100, 1);
        const userAvatar = document.getElementById('userAvatar');
        if (userAvatar) {
          userAvatar.style.transform = `scale(${scale})`;
        }
        if (isRecording) {
          requestAnimationFrame(animate);
        } else {
          if (userAvatar) userAvatar.style.transform = '';
        }
      }
      animate();
    }
  
    async function startRecording() {
      audioChunks = [];
  
      highlightSpeaker('user');
      startMicVisualizer(mediaStream);
  
      mediaRecorder = new MediaRecorder(mediaStream);
      mediaRecorder.start();
      isRecording = true;
  
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        unhighlightSpeaker('user');
        isRecording = false;
  
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        const formData = new FormData();
        formData.append('audio_data', audioBlob, 'input.wav');
  
        addMessage('Candidate', 'Processing');
        const res = await fetch('/ai/interview/transcribe', { method: 'POST', body: formData });
        const data = await res.json();
        if (data.transcript) {
          let convo = document.getElementById('conversation');
          convo.lastChild.innerHTML = `<p><strong>Candidate:</strong> ${data.transcript}</p>`;
  
          const qres = await fetch('/ai/interview/get_ai_question');
          const qdata = await qres.json();
          addMessage('Interviewer', qdata.question);
          speak(qdata.question);
  
          if (qdata.end_interview) {
            alert("Interview concluded.");
          }
        } else {
          alert("Error transcribing audio.");
        }
  
        mediaStream.getTracks().forEach(track => track.stop());
      };
    }
  
    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    }
  
    document.addEventListener('keydown', async (e) => {
      if (e.key === 'r' || e.key === 'R') {
        if (!isRecording) {
          await startRecording();
        } else {
          stopRecording();
        }
      }
    });
  
    document.getElementById('endInterview').onclick = async () => {
      const modal = document.getElementById('evaluationModal');
      const spinner = document.getElementById('evaluationSpinner');
      const content = document.getElementById('evaluationContent');
  
      modal.classList.remove('hidden');
      spinner.classList.remove('hidden');
      content.classList.add('hidden');
      content.innerText = "";
  
      try {
        const res = await fetch('/ai/interview/final_evaluation');
        const data = await res.json();
        content.innerText = "Final Evaluation:\n" + data.evaluation;
      } catch (err) {
        content.innerText = "Error fetching evaluation.";
      }
  
      spinner.classList.add('hidden');
      content.classList.remove('hidden');
    };
  
    function closeModal() {
      document.getElementById('evaluationModal').classList.add('hidden');
    }
  
    document.getElementById('startInterviewBtn').onclick = async () => {
      const jobFile = document.getElementById('jobFile').files[0];
      const resumeFile = document.getElementById('resumeFile').files[0];
  
      if (!jobFile || !resumeFile) {
        alert("Please upload both files.");
        return;
      }
  
      const formData = new FormData();
      formData.append('job_description', jobFile);
      formData.append('resume', resumeFile);
  
      try {
        const res = await fetch('/ai/interview/upload_context', { method: 'POST', body: formData });
        const data = await res.json();
  
        if (data.success) {
          document.getElementById('fileUploadModal').classList.add('hidden');
          interviewReady = true;
          fetchFirstQuestion(); // Now start
        } else {
          alert("Error uploading files. Please try again.");
        }
      } catch (err) {
        alert("Upload failed. Please try again.");
      }
    };
  
    // Initialize streams and show camera/screen feeds
    window.onload = async () => {
      document.getElementById('fileUploadModal').classList.remove('hidden');
  
      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        cameraStream = await navigator.mediaDevices.getUserMedia({ video: true });
        screenStream = await navigator.mediaDevices.getDisplayMedia({ video: true });
  
        // Camera Stream to user tile
        const userVideo = document.getElementById('userVideo');
        const userAvatar = document.getElementById('userAvatar');
        if (userVideo && cameraStream) {
          userVideo.srcObject = cameraStream;
          userVideo.style.display = 'block';
          if (userAvatar) userAvatar.style.display = 'none';
          userVideo.play();
        }
  
        // Screen Stream to screen tile
        const screenVideo = document.getElementById('screenVideo');
        const screenTile = document.getElementById('screenTile');
        if (screenVideo && screenStream) {
          screenVideo.srcObject = screenStream;
          screenTile.classList.remove('hidden');
          screenVideo.play();
        }
  
        console.log("Mic, camera, and screen permissions granted.");
      } catch (err) {
        console.error("Permission denied or error:", err);
        alert("Please allow mic, camera, and screen access to proceed.");
      }
    };
  </script>

</html>